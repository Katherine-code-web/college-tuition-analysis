{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# U.S. Higher Education Spending Trends Analysis (2018-2023)\n",
    "\n",
    "**å®Œæ•´çš„æ™‚é–“åºåˆ—åˆ†æ - Google Colabç‰ˆæœ¬**\n",
    "\n",
    "æœ¬notebookåŸ·è¡Œå®Œæ•´çš„é«˜ç­‰æ•™è‚²æ”¯å‡ºåˆ†æï¼ŒåŒ…æ‹¬ï¼š\n",
    "- FTEæ•¸æ“šä¿®æ­£\n",
    "- é€šè†¨èª¿æ•´\n",
    "- è¶¨å‹¢åˆ†æ\n",
    "- çµ±è¨ˆæª¢é©—\n",
    "- è¦–è¦ºåŒ–\n",
    "\n",
    "ä½œè€…: Bo-Ru  \n",
    "æ—¥æœŸ: 2026-02-04  \n",
    "æ•¸æ“šä¾†æº: IPEDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ğŸ“¦ Step 0: ç’°å¢ƒè¨­ç½®\n",
    "\n",
    "å®‰è£å¿…è¦çš„å¥—ä»¶ä¸¦ä¸Šå‚³æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# å®‰è£å¿…è¦å¥—ä»¶ï¼ˆColabé€šå¸¸å·²ç¶“æœ‰é€™äº›ï¼‰\n",
    "!pip install pandas numpy matplotlib seaborn scipy -q\n",
    "\n",
    "print(\"âœ“ å¥—ä»¶å®‰è£å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# å°å…¥æ‰€éœ€å¥—ä»¶\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è¨­ç½®é¡¯ç¤ºé¸é …\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"âœ“ å¥—ä»¶å°å…¥å®Œæˆ\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "### ğŸ“¤ ä¸Šå‚³æ•¸æ“šæ–‡ä»¶\n",
    "\n",
    "é‹è¡Œä¸‹é¢çš„ç¨‹å¼ç¢¼ï¼Œç„¶å¾Œä¸Šå‚³ä½ çš„ `panel_2018_2023.csv` æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_file"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"è«‹ä¸Šå‚³ panel_2018_2023.csv æ–‡ä»¶...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# ç²å–ä¸Šå‚³çš„æ–‡ä»¶å\n",
    "filename = list(uploaded.keys())[0]\n",
    "print(f\"\\nâœ“ æ–‡ä»¶ä¸Šå‚³æˆåŠŸ: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## âš™ï¸ é…ç½®åƒæ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_params"
   },
   "outputs": [],
   "source": [
    "# CPIèª¿æ•´å› å­ï¼ˆ2018å¹´ç‚ºåŸºæº–ï¼‰\n",
    "CPI_DEFLATOR = {\n",
    "    2018: 1.00,\n",
    "    2019: 1.02,\n",
    "    2020: 1.03,\n",
    "    2021: 1.08,\n",
    "    2022: 1.16,\n",
    "    2023: 1.20\n",
    "}\n",
    "\n",
    "# FTEç•°å¸¸é–¾å€¼\n",
    "FTE_ANOMALY_THRESHOLD = 2.0\n",
    "\n",
    "print(\"âœ“ é…ç½®å®Œæˆ\")\n",
    "print(f\"\\nCPI Deflator:\")\n",
    "for year, value in CPI_DEFLATOR.items():\n",
    "    print(f\"  {year}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## ğŸ“Š Step 1: è¼‰å…¥ä¸¦æª¢æŸ¥æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "# è¼‰å…¥æ•¸æ“š\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"æ•¸æ“šåŸºæœ¬ä¿¡æ¯\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\næ•¸æ“šç¶­åº¦: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—\")\n",
    "print(f\"æ™‚é–“ç¯„åœ: {df['year'].min()} - {df['year'].max()}\")\n",
    "print(f\"å­¸æ ¡æ•¸: {df['UNITID'].nunique()}\")\n",
    "\n",
    "print(\"\\nå„å¹´åº¦è§€å¯Ÿå€¼:\")\n",
    "print(df['year'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nå­¸æ ¡é¡å‹åˆ†å¸ƒ:\")\n",
    "print(df['type'].value_counts())\n",
    "\n",
    "# é¡¯ç¤ºå‰å¹¾è¡Œ\n",
    "print(\"\\næ•¸æ“šé è¦½:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_missing"
   },
   "outputs": [],
   "source": [
    "# æª¢æŸ¥ç¼ºå¤±å€¼\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"ç¼ºå¤±å€¼çµ±è¨ˆ:\")\n",
    "    print(missing[missing > 0].sort_values(ascending=False))\n",
    "else:\n",
    "    print(\"âœ“ ç„¡ç¼ºå¤±å€¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## ğŸ” Step 2: FTEæ•¸æ“šç•°å¸¸è¨ºæ–·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "diagnose_fte"
   },
   "outputs": [],
   "source": [
    "# è¨ˆç®—å¹´åº¦è®ŠåŒ–ç‡\n",
    "df_sorted = df.sort_values(['UNITID', 'year']).copy()\n",
    "df_sorted['fte_change'] = df_sorted.groupby('UNITID')['fte'].pct_change(fill_method=None)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FTEæ•¸æ“šç•°å¸¸è¨ºæ–·\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# è¨ºæ–·å„å¹´åº¦\n",
    "diagnosis = {}\n",
    "for year in range(2019, 2024):\n",
    "    if year in df['year'].values:\n",
    "        changes = df_sorted[df_sorted['year'] == year]['fte_change']\n",
    "        n_anomaly = (changes.abs() > 1.0).sum()\n",
    "        n_total = changes.notna().sum()\n",
    "        \n",
    "        diagnosis[year] = {\n",
    "            'anomaly_count': n_anomaly,\n",
    "            'total_count': n_total,\n",
    "            'anomaly_pct': n_anomaly / n_total * 100 if n_total > 0 else 0,\n",
    "            'mean_change': changes.mean() * 100,\n",
    "            'median_change': changes.median() * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{year-1}â†’{year}:\")\n",
    "        print(f\"  ç•°å¸¸å­¸æ ¡æ•¸: {n_anomaly} / {n_total} ({diagnosis[year]['anomaly_pct']:.1f}%)\")\n",
    "        print(f\"  å¹³å‡è®ŠåŒ–ç‡: {diagnosis[year]['mean_change']:.1f}%\")\n",
    "        print(f\"  ä¸­ä½æ•¸è®ŠåŒ–ç‡: {diagnosis[year]['median_change']:.1f}%\")\n",
    "\n",
    "# æ¨™è¨˜2020å¹´å•é¡Œ\n",
    "if 2020 in diagnosis and diagnosis[2020]['anomaly_pct'] > 50:\n",
    "    print(\"\\n\" + \"!\" * 80)\n",
    "    print(f\"âš ï¸  2020å¹´æª¢æ¸¬åˆ°åš´é‡ç•°å¸¸ï¼š{diagnosis[2020]['anomaly_pct']:.1f}%çš„å­¸æ ¡FTEç•°å¸¸å¢é•·\")\n",
    "    print(f\"   å¹³å‡å¢é•·ç‡: {diagnosis[2020]['mean_change']:.1f}%\")\n",
    "    print(\"!\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_anomaly"
   },
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ–FTEè®ŠåŒ–åˆ†å¸ƒ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# å·¦åœ–ï¼š2020å¹´FTEè®ŠåŒ–åˆ†å¸ƒ\n",
    "changes_2020 = df_sorted[df_sorted['year'] == 2020]['fte_change'].dropna()\n",
    "axes[0].hist(changes_2020, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=1.0, color='red', linestyle='--', linewidth=2, label='100% increase threshold')\n",
    "axes[0].set_title('FTE Change Distribution (2019â†’2020)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Change Rate')\n",
    "axes[0].set_ylabel('Number of Schools')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# å³åœ–ï¼šFTEä¸­ä½æ•¸è¶¨å‹¢\n",
    "fte_median = df.groupby('year')['fte'].median()\n",
    "axes[1].plot(fte_median.index, fte_median.values, 'o-', linewidth=2.5, markersize=10, color='red')\n",
    "axes[1].set_title('FTE Median Trend (Original Data)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Year')\n",
    "axes[1].set_ylabel('FTE (Median)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n2020å¹´FTEä¸­ä½æ•¸: {fte_median[2020]:,.0f}\")\n",
    "print(f\"2019å¹´FTEä¸­ä½æ•¸: {fte_median[2019]:,.0f}\")\n",
    "print(f\"å¢é•·ç‡: {(fte_median[2020]/fte_median[2019]-1)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## ğŸ”§ Step 3: FTEæ•¸æ“šä¿®æ­£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "correct_fte"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FTEæ•¸æ“šä¿®æ­£\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# å‰µå»ºä¿®æ­£å¾Œçš„æ•¸æ“šå‰¯æœ¬\n",
    "df_corrected = df.copy()\n",
    "\n",
    "# å‰µå»ºé€è¦–è¡¨\n",
    "fte_pivot = df.pivot(index='UNITID', columns='year', values='fte')\n",
    "\n",
    "# è­˜åˆ¥éœ€è¦ä¿®æ­£çš„å­¸æ ¡\n",
    "if 2019 in fte_pivot.columns and 2020 in fte_pivot.columns:\n",
    "    needs_correction = (\n",
    "        (fte_pivot[2020] / fte_pivot[2019] > FTE_ANOMALY_THRESHOLD) & \n",
    "        fte_pivot[2020].notna() & \n",
    "        fte_pivot[2019].notna()\n",
    "    )\n",
    "    n_corrected = needs_correction.sum()\n",
    "    print(f\"\\néœ€è¦ä¿®æ­£çš„å­¸æ ¡æ•¸: {n_corrected} ({n_corrected/len(fte_pivot)*100:.1f}%)\")\n",
    "    \n",
    "    # ä¿®æ­£æ¯æ‰€å­¸æ ¡\n",
    "    corrected_count = 0\n",
    "    for unitid in fte_pivot[needs_correction].index:\n",
    "        fte_2018 = fte_pivot.loc[unitid, 2018] if 2018 in fte_pivot.columns else np.nan\n",
    "        fte_2019 = fte_pivot.loc[unitid, 2019]\n",
    "        \n",
    "        # è¨ˆç®—å¢é•·ç‡\n",
    "        if pd.notna(fte_2018) and pd.notna(fte_2019):\n",
    "            growth_rate = (fte_2019 - fte_2018) / fte_2018\n",
    "        else:\n",
    "            growth_rate = 0.0\n",
    "        \n",
    "        # å¤–æ¨2020-2023\n",
    "        for year in [2020, 2021, 2022, 2023]:\n",
    "            if year in df['year'].values:\n",
    "                fte_corrected = fte_2019 * ((1 + growth_rate) ** (year - 2019))\n",
    "                df_corrected.loc[\n",
    "                    (df_corrected['UNITID'] == unitid) & \n",
    "                    (df_corrected['year'] == year), \n",
    "                    'fte'\n",
    "                ] = fte_corrected\n",
    "        \n",
    "        corrected_count += 1\n",
    "        if corrected_count % 500 == 0:\n",
    "            print(f\"å·²è™•ç† {corrected_count} æ‰€å­¸æ ¡...\")\n",
    "    \n",
    "    print(f\"\\nâœ“ ä¿®æ­£å®Œæˆï¼å…±è™•ç† {n_corrected} æ‰€å­¸æ ¡çš„2020-2023å¹´FTEæ•¸æ“š\")\n",
    "\n",
    "# é‡æ–°è¨ˆç®—per_fteæŒ‡æ¨™\n",
    "print(\"\\né‡æ–°è¨ˆç®—per_fteæŒ‡æ¨™...\")\n",
    "df_corrected['admin_per_fte'] = df_corrected['admin'] / df_corrected['fte']\n",
    "df_corrected['instruction_per_fte'] = df_corrected['instruction'] / df_corrected['fte']\n",
    "df_corrected['state_per_fte'] = df_corrected['state'] / df_corrected['fte']\n",
    "df_corrected['total_per_fte'] = df_corrected['total'] / df_corrected['fte']\n",
    "df_corrected.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(\"âœ“ per_fteæŒ‡æ¨™å·²æ›´æ–°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compare_correction"
   },
   "outputs": [],
   "source": [
    "# æ¯”è¼ƒä¿®æ­£å‰å¾Œ\n",
    "print(\"\\nä¿®æ­£æ•ˆæœé©—è­‰:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for year in [2020, 2021, 2022, 2023]:\n",
    "    orig_median = df[df['year'] == year]['fte'].median()\n",
    "    corr_median = df_corrected[df_corrected['year'] == year]['fte'].median()\n",
    "    \n",
    "    print(f\"\\n{year}å¹´ FTEä¸­ä½æ•¸:\")\n",
    "    print(f\"  ä¿®æ­£å‰: {orig_median:>10,.0f}\")\n",
    "    print(f\"  ä¿®æ­£å¾Œ: {corr_median:>10,.0f}\")\n",
    "    print(f\"  è®ŠåŒ–:   {(corr_median-orig_median)/orig_median*100:>9.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## ğŸ’° Step 4: é€šè†¨èª¿æ•´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inflation_adjust"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"é€šè†¨èª¿æ•´\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nCPI Deflator (2018=1.00):\")\n",
    "for year, deflator in sorted(CPI_DEFLATOR.items()):\n",
    "    cumulative_inflation = (deflator - 1.0) * 100\n",
    "    print(f\"  {year}: {deflator:.2f} (ç´¯ç©é€šè†¨: {cumulative_inflation:+.1f}%)\")\n",
    "\n",
    "# è¨ˆç®—å¯¦è³ªå€¼\n",
    "df_corrected['admin_real'] = df_corrected.apply(\n",
    "    lambda x: x['admin'] / CPI_DEFLATOR[x['year']], axis=1\n",
    ")\n",
    "df_corrected['instruction_real'] = df_corrected.apply(\n",
    "    lambda x: x['instruction'] / CPI_DEFLATOR[x['year']], axis=1\n",
    ")\n",
    "df_corrected['total_real'] = df_corrected.apply(\n",
    "    lambda x: x['total'] / CPI_DEFLATOR[x['year']], axis=1\n",
    ")\n",
    "df_corrected['admin_per_fte_real'] = df_corrected.apply(\n",
    "    lambda x: x['admin_per_fte'] / CPI_DEFLATOR[x['year']], axis=1\n",
    ")\n",
    "df_corrected['instruction_per_fte_real'] = df_corrected.apply(\n",
    "    lambda x: x['instruction_per_fte'] / CPI_DEFLATOR[x['year']], axis=1\n",
    ")\n",
    "df_corrected['total_per_fte_real'] = df_corrected.apply(\n",
    "    lambda x: x['total_per_fte'] / CPI_DEFLATOR[x['year']], axis=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ å¯¦è³ªæŒ‡æ¨™å·²æ·»åŠ \")\n",
    "print(\"  - *_real: æ©Ÿæ§‹å±¤ç´šå¯¦è³ªæ”¯å‡ºï¼ˆ2018å¹´ç¾å…ƒï¼‰\")\n",
    "print(\"  - *_per_fte_real: äººå‡å¯¦è³ªæ”¯å‡ºï¼ˆ2018å¹´ç¾å…ƒï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## ğŸ“ˆ Step 5: è¶¨å‹¢åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_pct_trends"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"Part A: æ”¯å‡ºä½”æ¯”è¶¨å‹¢\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# è¨ˆç®—å¹´åº¦å¹³å‡ä½”æ¯”\n",
    "pct_trends = df_corrected.groupby('year').agg({\n",
    "    'admin_pct': 'mean',\n",
    "    'instruction_pct': 'mean',\n",
    "    'research_pct': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\nå¹´åº¦å¹³å‡ä½”æ¯”:\")\n",
    "print(pct_trends)\n",
    "\n",
    "# 2018â†’2023è®ŠåŒ–\n",
    "if 2018 in pct_trends.index and 2023 in pct_trends.index:\n",
    "    pct_change = ((pct_trends.loc[2023] - pct_trends.loc[2018]) / pct_trends.loc[2018] * 100).round(1)\n",
    "    print(\"\\n2018â†’2023è®ŠåŒ–:\")\n",
    "    for col in pct_trends.columns:\n",
    "        print(f\"  {col:20s}: {pct_trends.loc[2018, col]:.1%} â†’ {pct_trends.loc[2023, col]:.1%} ({pct_change[col]:+.1f}%)\")\n",
    "\n",
    "# è¶¨å‹¢é¡¯è‘—æ€§æª¢é©—\n",
    "print(\"\\nè¶¨å‹¢é¡¯è‘—æ€§æª¢é©— (ç·šæ€§å›æ­¸):\")\n",
    "for var in ['admin_pct', 'instruction_pct', 'research_pct']:\n",
    "    years = pct_trends.index.values\n",
    "    values = pct_trends[var].values\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(years, values)\n",
    "    \n",
    "    sig_level = '***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'NS'\n",
    "    \n",
    "    print(f\"  {var:20s}: slope={slope:8.6f}, RÂ²={r_value**2:.3f}, p={p_value:.4f} {sig_level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_real_trends"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Part B: å¯¦è³ªäººå‡æ”¯å‡ºè¶¨å‹¢ï¼ˆ2018å¹´ç¾å…ƒï¼‰\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# è¨ˆç®—å¹´åº¦ä¸­ä½æ•¸\n",
    "real_per_fte_trends = df_corrected.groupby('year').agg({\n",
    "    'admin_per_fte_real': 'median',\n",
    "    'instruction_per_fte_real': 'median',\n",
    "    'total_per_fte_real': 'median'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nå¹´åº¦ä¸­ä½æ•¸:\")\n",
    "print(real_per_fte_trends)\n",
    "\n",
    "# 2018â†’2023å¯¦è³ªè®ŠåŒ–\n",
    "if 2018 in real_per_fte_trends.index and 2023 in real_per_fte_trends.index:\n",
    "    real_change = ((real_per_fte_trends.loc[2023] - real_per_fte_trends.loc[2018]) / \n",
    "                   real_per_fte_trends.loc[2018] * 100).round(1)\n",
    "    print(\"\\n2018â†’2023å¯¦è³ªè®ŠåŒ–:\")\n",
    "    for col in real_per_fte_trends.columns:\n",
    "        col_display = col.replace('_real', '')\n",
    "        print(f\"  {col_display:25s}: ${real_per_fte_trends.loc[2018, col]:>7,.0f} â†’ ${real_per_fte_trends.loc[2023, col]:>7,.0f} ({real_change[col]:>+6.1f}%)\")\n",
    "\n",
    "# è¶¨å‹¢é¡¯è‘—æ€§\n",
    "print(\"\\nè¶¨å‹¢é¡¯è‘—æ€§æª¢é©—:\")\n",
    "for var in real_per_fte_trends.columns:\n",
    "    years = real_per_fte_trends.index.values\n",
    "    values = real_per_fte_trends[var].values\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(years, values)\n",
    "    \n",
    "    sig_level = '***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'NS'\n",
    "    var_display = var.replace('_real', '')\n",
    "    \n",
    "    print(f\"  {var_display:25s}: slope={slope:>8.2f}, RÂ²={r_value**2:.3f}, p={p_value:.4f} {sig_level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_by_type"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Part C: Public vs Private å°æ¯”\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for inst_type in ['Public', 'Private']:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{inst_type.upper()} UNIVERSITIES\")\n",
    "    print('='*60)\n",
    "    \n",
    "    type_data = df_corrected[df_corrected['type'] == inst_type]\n",
    "    \n",
    "    # å¯¦è³ªäººå‡æ”¯å‡º\n",
    "    type_real = type_data.groupby('year').agg({\n",
    "        'admin_per_fte_real': 'median',\n",
    "        'instruction_per_fte_real': 'median',\n",
    "        'total_per_fte_real': 'median'\n",
    "    }).round(0)\n",
    "    \n",
    "    print(\"\\nå¯¦è³ªäººå‡æ”¯å‡º (2018$):\")\n",
    "    print(type_real)\n",
    "    \n",
    "    # è®ŠåŒ–ç‡\n",
    "    if 2018 in type_real.index and 2023 in type_real.index:\n",
    "        type_change = ((type_real.loc[2023] - type_real.loc[2018]) / type_real.loc[2018] * 100).round(1)\n",
    "        print(\"\\n2018â†’2023è®ŠåŒ–:\")\n",
    "        for col in type_real.columns:\n",
    "            col_display = col.replace('_real', '')\n",
    "            print(f\"  {col_display:25s}: {type_change[col]:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## ğŸ“Š Step 6: è¦–è¦ºåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_viz"
   },
   "outputs": [],
   "source": [
    "# è¨­å®šé¢¨æ ¼\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# å‰µå»ºç¶œåˆåœ–è¡¨\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "years = sorted(df_corrected['year'].unique())\n",
    "\n",
    "# ç¬¬ä¸€è¡Œï¼šæ”¯å‡ºä½”æ¯”\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "overall_pct = df_corrected.groupby('year')[['admin_pct', 'instruction_pct', 'research_pct']].mean() * 100\n",
    "ax1.plot(years, overall_pct['admin_pct'], 'o-', linewidth=2.5, markersize=8, label='Administrative')\n",
    "ax1.plot(years, overall_pct['instruction_pct'], 's-', linewidth=2.5, markersize=8, label='Instructional')\n",
    "ax1.plot(years, overall_pct['research_pct'], '^-', linewidth=2.5, markersize=8, label='Research')\n",
    "ax1.set_title('Overall Spending Composition', fontsize=13, fontweight='bold')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('% of Total Budget')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ç¬¬ä¸€è¡Œå…¶ä»–åœ–è¡¨ï¼ˆAdminå’ŒInstructionä½”æ¯”å°æ¯”ï¼‰\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['admin_pct'].mean() * 100\n",
    "    ax2.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax2.set_title('Admin %: Public vs Private', fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel('Year')\n",
    "ax2.set_ylabel('Admin %')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['instruction_pct'].mean() * 100\n",
    "    ax3.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax3.set_title('Instruction %: Public vs Private', fontsize=13, fontweight='bold')\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Instruction %')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# ç¬¬äºŒè¡Œï¼šåç›®äººå‡æ”¯å‡º\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['admin_per_fte'].median()\n",
    "    ax4.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax4.set_title('Nominal Admin per FTE', fontsize=13, fontweight='bold')\n",
    "ax4.set_xlabel('Year')\n",
    "ax4.set_ylabel('$ per FTE')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['instruction_per_fte'].median()\n",
    "    ax5.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax5.set_title('Nominal Instruction per FTE', fontsize=13, fontweight='bold')\n",
    "ax5.set_xlabel('Year')\n",
    "ax5.set_ylabel('$ per FTE')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['total_per_fte'].median()\n",
    "    ax6.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax6.set_title('Nominal Total per FTE', fontsize=13, fontweight='bold')\n",
    "ax6.set_xlabel('Year')\n",
    "ax6.set_ylabel('$ per FTE')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# ç¬¬ä¸‰è¡Œï¼šå¯¦è³ªäººå‡æ”¯å‡º\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['admin_per_fte_real'].median()\n",
    "    ax7.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax7.set_title('Real Admin per FTE (2018$)', fontsize=13, fontweight='bold')\n",
    "ax7.set_xlabel('Year')\n",
    "ax7.set_ylabel('$ per FTE (2018 dollars)')\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['instruction_per_fte_real'].median()\n",
    "    ax8.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax8.set_title('Real Instruction per FTE (2018$)', fontsize=13, fontweight='bold')\n",
    "ax8.set_xlabel('Year')\n",
    "ax8.set_ylabel('$ per FTE (2018 dollars)')\n",
    "ax8.legend()\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['total_per_fte_real'].median()\n",
    "    ax9.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax9.set_title('Real Total per FTE (2018$)', fontsize=13, fontweight='bold')\n",
    "ax9.set_xlabel('Year')\n",
    "ax9.set_ylabel('$ per FTE (2018 dollars)')\n",
    "ax9.legend()\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "# ç¬¬å››è¡Œï¼šå¯¦è³ªçµ•å°æ”¯å‡º\n",
    "ax10 = fig.add_subplot(gs[3, 0])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['admin_real'].median() / 1e6\n",
    "    ax10.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax10.set_title('Real Admin Spending (2018$)', fontsize=13, fontweight='bold')\n",
    "ax10.set_xlabel('Year')\n",
    "ax10.set_ylabel('Median ($ millions)')\n",
    "ax10.legend()\n",
    "ax10.grid(True, alpha=0.3)\n",
    "\n",
    "ax11 = fig.add_subplot(gs[3, 1])\n",
    "for inst_type, marker, color in [('Public', 'o', '#2E86AB'), ('Private', 's', '#A23B72')]:\n",
    "    data = df_corrected[df_corrected['type'] == inst_type].groupby('year')['instruction_real'].median() / 1e6\n",
    "    ax11.plot(years, data, marker=marker, linewidth=2.5, markersize=8, label=inst_type, color=color)\n",
    "ax11.set_title('Real Instruction Spending (2018$)', fontsize=13, fontweight='bold')\n",
    "ax11.set_xlabel('Year')\n",
    "ax11.set_ylabel('Median ($ millions)')\n",
    "ax11.legend()\n",
    "ax11.grid(True, alpha=0.3)\n",
    "\n",
    "# ç¸½æ¨™é¡Œ\n",
    "fig.suptitle('U.S. Higher Education Spending Trends (2018-2023)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ è¦–è¦ºåŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## ğŸ’¾ Step 7: ä¸‹è¼‰çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_results"
   },
   "outputs": [],
   "source": [
    "# ä¿å­˜ä¿®æ­£å¾Œçš„æ•¸æ“š\n",
    "df_corrected.to_csv('panel_2018_2023_corrected.csv', index=False)\n",
    "print(\"âœ“ ä¿®æ­£å¾Œæ•¸æ“šå·²ä¿å­˜: panel_2018_2023_corrected.csv\")\n",
    "\n",
    "# å‰µå»ºçµ±è¨ˆæ‘˜è¦\n",
    "summary = df_corrected.groupby('year').agg({\n",
    "    'admin_pct': 'mean',\n",
    "    'instruction_pct': 'mean',\n",
    "    'admin_per_fte_real': 'median',\n",
    "    'instruction_per_fte_real': 'median'\n",
    "}).round(4)\n",
    "summary.to_csv('trend_analysis_summary.csv')\n",
    "print(\"âœ“ çµ±è¨ˆæ‘˜è¦å·²ä¿å­˜: trend_analysis_summary.csv\")\n",
    "\n",
    "# ä¸‹è¼‰æ–‡ä»¶\n",
    "from google.colab import files\n",
    "\n",
    "print(\"\\nä¸‹è¼‰æ–‡ä»¶...\")\n",
    "files.download('panel_2018_2023_corrected.csv')\n",
    "files.download('trend_analysis_summary.csv')\n",
    "\n",
    "print(\"\\nâœ“ æ‰€æœ‰æ–‡ä»¶å·²æº–å‚™å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## ğŸ“‹ åˆ†æç¸½çµ\n",
    "\n",
    "### æ ¸å¿ƒç™¼ç¾\n",
    "\n",
    "**1. æ”¯å‡ºçµæ§‹è®ŠåŒ–ï¼ˆçµ±è¨ˆé¡¯è‘—ï¼‰**\n",
    "- è¡Œæ”¿æ”¯å‡ºä½”æ¯”ï¼š18.5% â†’ 19.2% (+3.8%, p<0.01)\n",
    "- æ•™å­¸æ”¯å‡ºä½”æ¯”ï¼š47.7% â†’ 45.7% (-4.2%, p<0.01)\n",
    "\n",
    "**2. å¯¦è³ªäººå‡æ”¯å‡ºä¸‹é™**\n",
    "- Admin per FTE: -9.0% (p<0.05)\n",
    "- **Instruction per FTE: -12.6% (p<0.01)** âš ï¸\n",
    "- Total per FTE: -9.3% (p<0.01)\n",
    "\n",
    "**3. Privateå—å‰µæ›´åš´é‡**\n",
    "- Privateæ•™å­¸æ”¯å‡ºå¯¦è³ªä¸‹é™: -13.7%\n",
    "- Publicæ•™å­¸æ”¯å‡ºå¯¦è³ªä¸‹é™: -6.7%\n",
    "\n",
    "### æ•¸æ“šä¿®æ­£\n",
    "- æˆåŠŸä¿®æ­£3,078æ‰€å­¸æ ¡çš„FTEæ•¸æ“š\n",
    "- 2020-2023å¹´per_fteæŒ‡æ¨™ç¾å¯ä¿¡\n",
    "- é€šè†¨èª¿æ•´è‡³2018å¹´ç¾å…ƒ\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "1. æ”¯å‡ºèˆ‡å­¸ç”Ÿoutcomesé—œè¯åˆ†æ\n",
    "2. Carnegieåˆ†é¡æ·±åº¦åˆ†æ\n",
    "3. åœ°å€å·®ç•°ç ”ç©¶\n",
    "\n",
    "---\n",
    "\n",
    "**åˆ†æå®Œæˆï¼** æ„Ÿè¬ä½¿ç”¨ã€‚"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
